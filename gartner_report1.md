## Конспект отчёта Гартнер по инструментам для интеграции данных

#### Ссылка на отчёт https://www.gartner.com/doc/reprints?id=1-1OA35PNQ&ct=190715&st=sb&mkt_tok=eyJpIjoiWXpRelpHTmtaRFJpTW1ObSIsInQiOiI0T0doVTZpOGRhVk9nMVhqaE9qQnlhdHpTR2h5eENZRXhOaXpKb0RmM0pQOVVFUk5kYitvYU45RzNtRTBQbTFaNE1VbzhzSjFcLzhKdjNKMlowTUVnRnBcL21rUGY2WWlsMlwvXC9FUDhxajEyRnlvclZPOVpMN1p1TndzTjRmbzloZVcifQ%3D%3D

* Стиль предоставления данных для выполнения задач по их интеграции
* Активные и пассивные метаданные - ключевая разница в том, что пассивные формируются на стадии проектирования хранилища и меняются лишь вручную (описаны в документации или технических метаданных). Активные могут изменяться с течением времени и адаптированы под методы машинного обучения
* Цель в автоматизации проектирования интеграции данных и построения инфраструктуры (либо рекомендательной системы)
* Оптимизированная и воспроизводимая аналитика

* Сценарии интеграции данных:
1. Оптимизированная аналитика
2. Доставка данных для MDM-систем
3. Согласованность данных между операциионными приложениями
4. Сбор и обмен данными об организации с заинтересованными лицами
5. Оркестрация дата-сервисов
6. Миграция данных и их консолидация
7. Поддержка управления данными (сбор, аудит, обмен, мониторинг, способность признать сходный характер данных)

* Данные как актив
* NoSQL - Hadoop, нереляционные базы, облачные хранилища
* Аналитические репозитории управления данными
* 3 типа нереляционных баз данных - хранилища ключевых значений, графические базы, базы документов
* Современные стили интеграции - виртуализация данных, подготовка и интеграция потоковых данных
* Компания Actian - продукт DataConnect (простота, только пакетная аналитика)
* Adeptia - Adeptia Connect (для гибридных платформ, слабость в управлении метаданными)
* Denodo - Denodo Platform (виртуализация данных, логическая абстракция при объединении данных, проблемы с универсальностью при стыковке виртуализации с другими стилями доставки данных - групповые и пакетные ETL, дорого)
* Hitachi Vantara - Pentaho Data Integration, Hitachi Streaming Data Platform (HSDP) и Hitachi Data Instance Director (HDID) (стали делать упор на интернет вещей, синергия инструментов интеграции с набором технологий по управлению данными, нет признания дата-сообществом)
* IBM -  IBM InfoSphere Information Server, IBM InfoSphere Classic Federation Server, IBM InfoSphere Data Replication, IBM App Connect, IBM Streams и IBM Data Refinery (самая крупная 11 тыс. клиентов-организаций, богатый функционал, поддержка различных стилей интеграции данных как современных, так и традиционных - репликация, пакетная обработка, синхронизация и интеграция потоковых данных, бренд, слабый стиль виртуализации данных, недостаточная поддержка межоблачной интеграции, дорого, сложность обновления инструментов)
* Informatica - PowerCenter, PowerExchange, Data Replication, B2B Data Transformation, B2B Data Exchange, Data Integration Hub, Data Services, Intelligent Cloud Services, Big Data Management, Big Data Integration Hub, Big Data Streaming, Enterprise Data Catalog, Enterprise Data Preparation и Edge Data Streaming, 10 тыс. клиентов - (пилят движок CLAIRE - автоматизация интеграции, включая обнаружение метаданных, каталогизация, линейный анализ, анализ влияния, рекомендации на основе AI, развитый функционал поддержки гибридных, облачных и многооблачных хранилищ, активно увеличивают долю рынка, развитая партнерская сеть, дорого)
* Information Builder - Omni-Gen data integration platform, iWay Service Manager, iWay DataMigrator и iWay Universal Adapter Suite (интеграция с MDM и инструмента управления качеством, слабые управление метаданными и функционал моделирования)
* Microsoft - SQL Server Integration Services (SSIS), Azure Data Factory (ADF) - (низкая стоимость владения, простота, гибридная интеграция, универсальность платформы, сложность миграции, негативные отзывы по работе с метаданными и моделированием, включая активные метаданные)
* Oracle - Oracle Data Integration Platform Cloud Service включая Oracle GoldenGate Cloud Service и Oracle Data Integrator Cloud Service), Oracle GoldenGate, Oracle Data Integrator (ODI), Oracle Big Data SQL, Oracle Service Bus и Oracle Integration Cloud Service, 12 тыс. клиентов - обширные сценарии репликации и интеграции потоковых данных, распределенные https и RESTful API, поддержка Kafka, Spark, дорого, клиенты слабо знают о современных сценариях интеграции (гибридная, активные метаданные, используют лишь групповую, пакетную интеграцию)
* Qlik (Attunity) - Attunity Replicate, Attunity Compose, Attunity Visibility и Attunity Enterprise Manager, 2500 клиентов (простота, надежная репликация, автоматическая генерация кода, отсутствие поддержки стилей интеграции, отличающихся от репликации/синхронизации)
* SAP - лидер рынка по числу организаций, 60 тыс., SAP Data Services, SAP Replication Server, SAP Landscape Transformation Replication Server, SAP Data Hub, SAP HANA и SAP Cloud Platform Integration Suite. SAP HANA platform включает SAP HANA Smart Data Integration (для групповой/пакетной и низкочастотной доставки данных), SAP HANA Smart Data Access (виртуализации данных) и SAP HANA Streaming Analytics (аналитика потоковых данных) - широкий функционал, активные метаданные, единая среда, развитая экосреда и партнерская сеть, дорого и сложность администрирования
* SAS - SAS Data Management, SAS Data Integration Studio, SAS Federation Server, SAS/ACCESS, SAS Data Loader для Hadoop, SAS Data Preparation и SAS Event Stream Processing, 14 тыс. организаций, опенсорсный проект по управлению метаданными с ODPi Egeria, активные метаданные, машинное обучение в метаданных, хороший послепродажный сервис, отдельное место подготовке данных SAS Data Preparation, дорого, сложность развертывания
* SnapLogic - SnapLogic Intelligent Integration Platform - очень богатые возможности интеграции данных, свыше 500 коннекторов, низкая цена, есть триальная версия, качество документации, устаревший интерфейс
* Syncsort - Syncsort Connect (высокая производительность ETL и низкая стоимость владения, не хватает функционала по управлению метаданными)
* Talend - Talend Open Studio, Talend Data Fabric, Talend Data Management Platform, Talend Big Data Platform, Talend Data Services Platform, Talend Integration Cloud и Talend Stitch Data Loader (хорошая платформа для гибридной и многооблачной интеграции, сообщество, поддержка опенсорсных технологий Apache Beam, Spark и Kafka, растущие цены, онлайн-документация, миграция и модернизация, проблемы с партнерской сетью)
* TIBCO Software - TIBCO Data Virtualization (TDV), TIBCO Cloud Integration, TIBCO EBX, TIBCO StreamBase, TIBCO Messaging и TIBCO Spotfire. TIBCO Messaging включает TIBCO FTL, TIBCO eFTL, TIBCO Flogo Enterprise and TIBCO Enterprise Message Service (широкая поддержка традиционных и перспективных стилей доставки данных, динамическое распределение большого объема данных среди множества процессов с помощью Apache Drill, поддержка Elasticsearch, хорошие возможности интеграции потоковых данных и очередей брокеров сообщений, сильная виртуализация данных, дефицит специалистов по продукты, слабая комплескная поддержка традиционных стилей доставки данных с пакетной аналитикой)
* программы-историки для кэширования данных

* 7 стилей доставки данных:
1. Групповая/пакетная (bulk/batch) - однопроходная или многопроходная/шаговая обработка источника данных с получением полного файла данных после завершения работы до начала работы потребителя данных
2. Оркестровка служб данных - возможность развертывания любого из других стилей интеграции данных, но со специфической возможностью взаимодействия со службами приложений (логические потоки, интерфейсы, конечные пользовательские интерфейсы и т.д.)
3. Виртуализация данных - использование логических представлений данных, которые могут быть кэшированы в различных формах в рамках сервера приложений интеграции данных или систем/памяти, управляемых этим сервером приложений
4. Репликация данных - простая копия данных из одного места в другое, всегда в физическое хранилище
5. Синхронизация данных - может использовать любую форму интеграции данных. Однако особое внимание уделяется установлению и поддержанию согласованности между двумя отдельными и управляемыми независимо друг от друга экземплярами создания, чтения, обновления, удаления (CRUD) общих, логически последовательных моделей данных для использования в целях обеспечения согласованности оперативных данных
6. Движение данных, ориентированное на сообщения - использует единую запись в инкапсулированном объекте. Это может включать или не включать внутреннюю структуру (XML), внешнюю структуру (электронный обмен данными) и источник, который предоставляет свои данные для принятия мер в процессе интеграции данных
7. Интеграция потоковых данных - состоят из наборов данных, которые следуют согласованному содержанию и структуре в течение длительного периода времени, и большого количества записей, которые эффективно сообщают об изменениях состояния подключенного устройства или приложения, или постоянно обновляют записи новыми значениями. Потоковая обработка/обработка событий включает модели событий, связанных со строковой целостностью данных. Модели могут разбиваться на отдельные потоки обработки
* Реляционные базы, плоские файлы, XML, старые несвязанные данные, очереди сообщений, потоковые данные
* Автоматизированное обнаружение метаданных - профилирование новых источников данных для обеспечения согласованности с существующими источниками
* Обнаружение метаданных на основе машинного обучения
* Примеры развертывания сервисов в производственной среде и возможности работы в среде разработки
* MDM, управление метаданными, каталогизация данных
* Решение для управления данными в аналитике - data management solution for analytics
* "Лидеры" рынка средств интеграции данных способны поддерживать полный спектр стилей доставки данных и позволяют сочетать различные стили доставки данных (например, виртуализация данных и ETL)
* bulk/batch - ETL
* В 2019 году "претенденты" добились значительных успехов в понимании того, что подготовка данных для самообслуживания, репликация данных, интеграция в облако и виртуализация данных больше не являются отличительн
ыми чертами, а должны обладать возможностями в рамках более широкого решения по интеграции метаданных
* виртуализация данных может управлять очередями сообщений или включать базы данных в качестве репозиториев переполнения кэша для легкого извлечения и/или в качестве техники оптимизации.
* Визионеры сконцентрировались на том, что будет востребовано в будущем:
- интеграция данных с использованием машинного обучения
- безсерверные платформы с поддержкой мультиоблачной или гибридной интеграции
- рост спроса на коннекторы, API/микросервисы
- упор на активные метаданные, автоматизация интеграции (шаблоны для повторного использования)
* Нишевые игроки слабы в создании платформы для комплексного использования, в остальном по функционалу и цене могут покрывать потребности клиентов, продолжают оставаться на плаву, так как 80% продолжают нуждаться в групповой/пакетной интеграции данных
* В контексте цифрового бизнеса кратковременные возможности или моменты времени, которые приводят в движение серию мероприятий с участием людей, предприятий и т.д. Они хотят использовать данные, чтобы воспользоваться этими моментами, что потребует поддержки интеграции данных, включающей в себя ориентацию на потоковые/событийные возможности
* Эпоха интеграционных инструментов на основе метаданных
* Метаданные побочный продукт проектирования и управления платформами интеграции
* Графический анализ обеспечит необходимые динамические структуры данных для внедрения возможностей машинного обучения в платформы интеграции данных
* Интегрированных данных по схеме, предназначенной для аналитики и использования в науке о данных
* Решающее значение приобретает сочетание подходов к интеграции данных, охватывающее как физическую доставку до виртуализированных хранилищ, так и групповое/пакетное перемещение данных с последующим детальным распространением их по событиям
* Данные постоянно обновляются и находятся в движении, поэтому их смешивание часто непрактично, поэтому растет спрос на коннекторы к источникам данных
* Распределение необходимой вычислительной нагрузки на параллельные процессы в Хадупе, альтернативных несопоставимых хранилищах и озерах данных будет и далее способствовать расширению возможностей инструментов интеграции данных по взаимодействию, передаче данных и выполнению задач интеграции на новых платформах, связанных с данными и анализом
* Интеграция данных занимает центральное место в корпоративной инфраструктуре управления данными
* выручка рынка инструментов интеграции данных в 2018 году составила чуть более 3,2 млрд долл. США
* Интеграция данных должна стать проактивной, чтобы воспользоваться бизнес-возможностями (!!!)
* Обширная поддержка метаданных для любых данных, где бы они ни находились (!!!)
* Инструменты интеграции данных будут обеспечивать постоянную обратную связь в отношении профилей, качества, случаев использования, точек доступа, контекста и анализа содержания интегрированных массивов данных. Графический анализ всех возможных типов метаданных обеспечит получение необходимой информации для внедрения возможностей машинного обучения в деятельность по интеграции данных (это называется "активный анализ метаданных", который теперь необходим и дифференцирован)
* Использование машинного обучения в интеграции данных (!!!)
* Такие подходы, как обработка естественного языка, могут облегчить решение интеграционных проблем и потенциально увеличить время, затрачиваемое на оценку, уменьшить сложность и расширить возможности менее технических ролей при решении задач интеграции данных. Основное внимание уделяется технологиям интеграции данных на базе AI в таких областях, как взаимодействие через чат-ботов или голосовую связь, автоматизация создания потоков данных с помощью новейших действий и интеллектуального картирования данных, * Автономная оптимизация для сочетания традиционного развертывания с современными инфраструктурными практиками
* Интеграция данных лежит в основе динамической структуры данных
* Интеграция данных становится обязанностью каждого (!!!!!!)
* Интерес к функциям интеграции данных, предоставляемым в "песочнице" для поддержки аналитики, растет. Такой подход позволяет доставлять данные и манипулировать ими физическим или виртуальным путем для объединения, независимо от того, где они находятся. Она также поощряет экспериментирование с новыми моделями и создание новых моделей для использования
* Организации нуждаются в инструментах интеграции данных, чтобы обеспечить возможности для подготовки данных для самообслуживания, т.е. в применении нетехническими пользователями
* Разнообразные интерфейсы для интеграции различных типов данных (!!!)
* Организации приступили к интеграции данных и интеграции прикладных программ на основе синергии, с тем чтобы использовать их взаимосвязь (!!!)
* Источники данных для платформ интеграции данных (типы структур данных):
1. Реляционные базы данных
2. Нереляционные базы данных
3. Различные форматы файлов
4. XML
5. Пакетные приложения, такие как приложения для CRM и управления цепочками поставок.
6. SaaS и облачные приложения и источники данных
7. Отраслевые стандартные форматы сообщений, такие как электронный обмен данными (ЭОД), Международный форум здравоохранения седьмого уровня (МРЗ-7) и Общество всемирной межбанковской финансовой телекоммуникации (СВИФТ).
8. Среды параллельной распределенной обработки, такие как распределенная файловая система Hadoop (HDFS) и другие репозитории нереляционных типов, такие как графики, таблицы, хранилища документов и СУБД типа "ключ-значение".
9. Очереди сообщений, включая очереди, предоставляемые промежуточным программным обеспечением для интеграции приложений и стандартными продуктами (например, Java Message Service).
11. Типы данных менее структурированного характера, такие как данные, связанные с социальными сетями, потоками веб-кликов, электронной почтой, веб-сайтами, офиснми инструментами и контентом.
12. Новые источники, такие как данные о репозиториях в памяти (in-memory repositories), мобильных платформах и прикладных космических технологиях
13. Скрапирование экрана (screen-scraping) и/или моделирование взаимодействия с пользователем (например, сценарии взаимодействия с Интернетом, 3270 или VT100 терминалами и т.д.).
* Режимы взаимодействия с различными типами структур данных:
1. Групповая/пакетная доставка
2. Струйная подача данных.
3. Сбор данных об изменениях данных.
4. Потоковая/событийная доставка данных.
* Виды перемещения данных:
1. Физическое перемещение групповых(объемных)/пакетных данных.
2. Виртуализация данных.
3. Ориентированный на сообщения подход.
4. Синхронизация данных.
5. Репликация между гомогенными и гетерогенными СУБД и схемами.
6. Миграция данных между версиями хранилища.
* Виды задержек доставки данных:
1. Плановая серийная поставка
2. Потоковая (в режиме реального времени или близкая к ней) доставка.
3. Предоставление данных на основе событий после их идентификации (срабатывание триггера)
* Виды преобразования данных:
1. Основные преобразования, такие как приведение типов данных, работа со строками и простые вычисления.
2. Преобразования промежуточной сложности, такие как поиск и замена операций, агрегирование, обобщение, обобщение, интегрированные временные ряды, детерминированное согласование и управление медленно меняющимися параметрами.
3. Комплексные преобразования, такие как сложные операции обработки текста в свободной форме, мультимедийные файлы и шаблоны/события в больших данных.
* Управление и моделирование метаданными принимают всё большее значение:
1. Автоматизированное обнаружение и получение метаданных из источников данных, приложений и других инструментов.
2. Разграничение взаимосвязей между моделями данных и моделями бизнес-процессов
3. Создание и обслуживание моделей данных
4. Картирование и рационализация физико-логических моделей
5. Способность определять отношения между моделью и моделью с помощью графического отображения уровня атрибутов
6. Отчетность по анализу линейности и воздействия в графическом и табличном форматах
7. Открытое хранилище метаданных с возможностью двунаправленного обмена метаданными с другими инструментами.
8. Автоматизированная синхронизация метаданных в нескольких экземплярах инструментов
9. Возможность расширения хранилища метаданных с помощью определяемых клиентом атрибутов метаданных и взаимосвязей
10. Документирование определений реализации проекта/программы и принципов проектирования в поддержку деятельности по определению требований.
11. Интерфейс бизнес-аналитика/пользователя для просмотра метаданных и работы с ними
* Поточный скоринг и оценка данных, проходящих через все процессы
* Общие метаданные (единое хранилище) и/или возможность обмена метаданными между всеми компонентами и способами предоставления данных
* Развернутая функциональность может быть вызвана через веб-интерфейс служб
* Взаимодействие с сервис-репозиториями и реестрами услуг
* Поставщики, которые демонстрируют наивысшую степень видения, слушают и понимают желания и потребности покупателей, и могут формировать или улучшать их с помощью дополнительных изменений

